LinearRegression
장점 : 구현하기 쉽고, 모형의 결과를 쉽게 이해할 수 있다.
독립변수와 종속변수 간의 관계를 쉽게 파악할 수 있다.
매우 큰 데이터 세트와 희소한 데이터 세트에도 잘 동작한다.

단점 :
1. 선형관계로 제한, 그들 사이에 직선 관계가 있다고 가정해서 때때로 올바르지 않음
2. 종속 변수의 평균만 봄, 종속변수의 극단을 살펴볼 필요가 있을 때 어려움, 평균이 단일 변수에 대한 완전한 설명이 아닌 것처럼 선형 회귀는 변수 간의 관계에 대한 완전한 설명이 아님. 분위수 회귀를 사용해야 문제 해결 가능
3. 특이치에 민감
4. 선형회귀는 데이터가 독립적이라고 가정하지만 항상 합리적인 것은 아님. 다중 레벨 모델을 사용해서 해결 가능
5. 계수의 값들이 왜 그런지 명확하지 않을 때가 있다. 특히 데이터셋의 특성이 서로 깊게 연간되어 있을 때 그러하다
류에도 널리 사용된다.

KNN
장점:
1. 기준 분류 체계 값을 모두 검사하여 비교하므로 정확도가 높음, 수치 기반 데이터 분류 작업에서 성능 우수 
학습데이터의 수가 충분하다면 좋은 성능을 낸다.
2. 비교하여 가까운 상위 k개의 데이터만 활용하기 때문에 오류 데이터는 비교 대상에서 제외되어 오류 데이터가 
결과에 영향을 미치지 않음, 학습 데이터의 노이즈에 크게 영향을 받지 않는다.
단점 :
1.적절한 K의 선택이 중요하다
2.기존의 모든 데이터를 비교해야하기 때문에 데이터가 많으면 많을수록 처리시간 증가, 분류 단계가 느리다
