{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TExiS7kG4Is",
        "outputId": "ba9655da-0e91-453f-95e4-b2ef95d22503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 9, 'max_leaf_nodes': 20, 'min_samples_split': 2}\n",
            "Single Tree Accuracy: 0.87\n",
            "Average Single Tree Accuracy: 0.8637999999999999\n",
            "Ensemble Accuracy: 0.8695\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 데이터셋 생성\n",
        "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 결정 트리 하이퍼파라미터 최적화\n",
        "param_grid = {\n",
        "    'max_depth': [6, 9, None],\n",
        "    'max_leaf_nodes': [10, 20, None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# 최적 모델로 테스트 정확도 확인\n",
        "best_tree = grid_search.best_estimator_\n",
        "print(\"Single Tree Accuracy:\", best_tree.score(X_test, y_test))\n",
        "\n",
        "# 랜덤 포레스트 구현\n",
        "np.random.seed(42)\n",
        "subsets = [np.random.choice(len(X_train), len(X_train), replace=True) for _ in range(100)]\n",
        "\n",
        "# 서브셋별 결정 트리 학습\n",
        "single_tree_accuracies = []\n",
        "for subset in subsets:\n",
        "    tree = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n",
        "    tree.fit(X_train[subset], y_train[subset])\n",
        "    single_tree_accuracies.append(tree.score(X_test, y_test))\n",
        "\n",
        "print(\"Average Single Tree Accuracy:\", np.mean(single_tree_accuracies))\n",
        "\n",
        "# 다수결 앙상블\n",
        "from scipy.stats import mode\n",
        "\n",
        "all_predictions = []\n",
        "for subset in subsets:\n",
        "    tree = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n",
        "    tree.fit(X_train[subset], y_train[subset])\n",
        "    all_predictions.append(tree.predict(X_test))\n",
        "\n",
        "# 다수결 방식으로 최종 예측 생성\n",
        "final_predictions = np.squeeze(mode(all_predictions, axis=0).mode)\n",
        "\n",
        "# 앙상블 정확도 계산\n",
        "from sklearn.metrics import accuracy_score\n",
        "ensemble_accuracy = accuracy_score(y_test, final_predictions)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)"
      ]
    }
  ]
}