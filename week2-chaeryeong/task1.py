# -*- coding: utf-8 -*-
"""task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wba48Ek5k50Jtr108zOGyVDI2bh3z6rh
"""

from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
import matplotlib.pyplot as plt

# 데이터 로드 및 준비
iris = load_iris()
X = iris.data[:, 3].reshape(-1, 1)  # 꽃잎 너비
y = (iris.target == 2).astype(int)  # Iris virginica 여부

# 데이터 정보 출력
print("Feature names:", iris.feature_names)
print("Target names:", iris.target_names)
print("Data shape:", X.shape)

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("Training set size:", X_train.shape)
print("Test set size:", X_test.shape)

# 모델 학습 및 평가
model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# 정확도
accuracy = accuracy_score(y_test, y_pred)
print("Model accuracy (Accuracy):", accuracy)

# 확률 계산
probabilities_test = model.predict_proba(X_test)[:, 1]
print("Probabilities for test data:", probabilities_test)

# 결정 경계 시각화
x_values = np.linspace(0, 3, 1000).reshape(-1, 1)
probabilities = model.predict_proba(x_values)[:, 1]

plt.figure(figsize=(8, 6))
plt.plot(x_values, probabilities, color="green", label="Iris Virginica Probability")
plt.axvline(x=x_values[np.argmax(probabilities >= 0.5)], color="red", linestyle="--", label="Decision Boundary")
plt.xlabel("Petal width (cm)")
plt.ylabel("Probability")
plt.title("Logistic Regression Decision Boundary")
plt.legend()
plt.grid()
plt.show()

# 분석:
# 모델은 테스트 세트에서 높은 정확도(1.0)를 달성하여 데이터셋을 잘 분류함을 보여줍니다.
# 결정 경계는 꽃잎 너비(petal width)를 기준으로 Virginica 품종과 나머지 품종을 효과적으로 구분합니다.