{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 목표\n",
        "결정 트리를 사용해 moons 데이터셋 분류 문제를 해결하고, 랜덤 포레스트로 정확도를 향상시켜 보세요."
      ],
      "metadata": {
        "id": "VeBIat935lMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 데이터 준비\n",
        "- `make_moons(n_samples=10000, noise=0.4)`를 사용해 데이터를 생성하세요.\n",
        "- 데이터를 훈련 세트(80%)와 테스트 세트(20%)로 나누세요(`train_test_split` 사용)."
      ],
      "metadata": {
        "id": "BTQrurse5mKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 생성\n",
        "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
        "\n",
        "# 훈련 세트와 테스트 세트로 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3g5z7X7w56pN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 결정 트리 하이퍼파라미터 최적화\n",
        "- `GridSearchCV`를 사용해 결정 트리의 `max_depth`, `max_leaf_nodes` 등 최적의 하이퍼파라미터를 찾으세요.\n",
        "- 최적의 하이퍼파라미터로 훈련된 모델의 테스트 정확도를 확인하세요.\n"
      ],
      "metadata": {
        "id": "ZJ5xIoUe5oIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 결정 트리 모델 설정\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# 하이퍼파라미터 그리드 설정\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
        "    'max_leaf_nodes': [10, 15, 20, 25, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# GridSearchCV 실행\n",
        "grid_search = GridSearchCV(tree_clf, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# 최적의 모델 테스트 정확도 확인\n",
        "best_tree = grid_search.best_estimator_\n",
        "test_accuracy = best_tree.score(X_test, y_test)\n",
        "print(\"Single Tree Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DNqN44w599u",
        "outputId": "603c5632-3e15-4535-87b4-e9242e13b26f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
            "Best Parameters: {'max_depth': 8, 'max_leaf_nodes': 25, 'min_samples_split': 2}\n",
            "Single Tree Accuracy: 0.872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 랜덤 포레스트 구현\n",
        "- 훈련 세트를 랜덤하게 샘플링한 서브셋을 생성하세요(100개의 서브셋).\n",
        "- 각 서브셋에 대해 결정 트리를 훈련시키고 정확도를 확인하세요."
      ],
      "metadata": {
        "id": "ZD0oKFLD5p-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "n_trees = 100  # 서브셋 개수\n",
        "subsets = []   # 서브셋 저장 리스트\n",
        "trees = []     # 학습된 결정 트리 저장\n",
        "\n",
        "# 랜덤 서브셋 생성 및 결정 트리 학습\n",
        "for i in range(n_trees):\n",
        "    X_subset, y_subset = resample(X_train, y_train, random_state=i)\n",
        "    tree = DecisionTreeClassifier(**best_params, random_state=i)\n",
        "    tree.fit(X_subset, y_subset)\n",
        "    subsets.append((X_subset, y_subset))\n",
        "    trees.append(tree)\n",
        "\n",
        "# 각 트리 정확도 저장 리스트\n",
        "tree_accuracies = []\n",
        "\n",
        "# 각 트리의 예측값과 정확도 확인\n",
        "predictions = np.zeros((n_trees, len(X_test)))\n",
        "\n",
        "for idx, tree in enumerate(trees):\n",
        "    y_pred = tree.predict(X_test)\n",
        "    predictions[idx] = y_pred\n",
        "\n",
        "    # 각 트리 정확도 저장\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    tree_accuracies.append(acc)\n",
        "\n",
        "# 단일 트리 평균 정확도 계산\n",
        "avg_single_tree_accuracy = np.mean(tree_accuracies)\n",
        "print(f\"Average Single Tree Accuracy: {avg_single_tree_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRhRKylK6Abt",
        "outputId": "c14bfeb1-03f7-444e-fe7d-1b49c2f65fd5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Single Tree Accuracy: 0.8634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 다수결 앙상블\n",
        "- 테스트 데이터에 대해 100개의 결정 트리의 예측값을 모으세요.\n",
        "- 다수결 방식으로 최종 예측을 생성하고 정확도를 측정하세요."
      ],
      "metadata": {
        "id": "IPIyfuMh5rp4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wJavGV65b7D",
        "outputId": "2530935b-be7d-4e7e-a461-80fe0458612e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 0.8645\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "# 각 트리의 예측값 모으기\n",
        "predictions = np.zeros((n_trees, len(X_test)))\n",
        "\n",
        "for idx, tree in enumerate(trees):\n",
        "    predictions[idx] = tree.predict(X_test)\n",
        "\n",
        "# 다수결 앙상블\n",
        "ensemble_predictions, _ = mode(predictions, axis=0)\n",
        "ensemble_predictions = ensemble_predictions.ravel()\n",
        "\n",
        "# 앙상블 정확도 확인\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n"
      ]
    }
  ]
}