{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33a3b3d1-89d4-47dc-b274-29b12752c04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 하이퍼파라미터: {'max_depth': 10, 'max_leaf_nodes': 20}\n",
      "결정 트리의 테스트 정확도: 0.87\n",
      "랜덤 포레스트의 테스트 정확도: 0.8505\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot cast array data from dtype('float64') to dtype('int64') according to the rule 'safe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# 4. 다수결 앙상블\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# 100개의 결정 트리 예측값을 모으고 다수결 방식으로 최종 예측 생성\u001b[39;00m\n\u001b[0;32m     48\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([tree\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m random_forest\u001b[38;5;241m.\u001b[39mestimators_])\n\u001b[1;32m---> 49\u001b[0m majority_votes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mbincount(x)\u001b[38;5;241m.\u001b[39margmax(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, arr\u001b[38;5;241m=\u001b[39my_preds)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# 다수결 앙상블 방식의 정확도 측정\u001b[39;00m\n\u001b[0;32m     52\u001b[0m ensemble_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, majority_votes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\shape_base.py:379\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    378\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 379\u001b[0m res \u001b[38;5;241m=\u001b[39m asanyarray(func1d(inarr_view[ind0], \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[0;32m    385\u001b[0m buff \u001b[38;5;241m=\u001b[39m zeros(inarr_view\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m res\u001b[38;5;241m.\u001b[39mshape, res\u001b[38;5;241m.\u001b[39mdtype)\n",
      "Cell \u001b[1;32mIn[35], line 49\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# 4. 다수결 앙상블\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# 100개의 결정 트리 예측값을 모으고 다수결 방식으로 최종 예측 생성\u001b[39;00m\n\u001b[0;32m     48\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([tree\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m random_forest\u001b[38;5;241m.\u001b[39mestimators_])\n\u001b[1;32m---> 49\u001b[0m majority_votes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mbincount(x)\u001b[38;5;241m.\u001b[39margmax(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, arr\u001b[38;5;241m=\u001b[39my_preds)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# 다수결 앙상블 방식의 정확도 측정\u001b[39;00m\n\u001b[0;32m     52\u001b[0m ensemble_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, majority_votes)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot cast array data from dtype('float64') to dtype('int64') according to the rule 'safe'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. 데이터 준비\n",
    "# make_moons를 사용해 데이터를 생성\n",
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
    "\n",
    "# 훈련 세트(80%)와 테스트 세트(20%)로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. 결정 트리 하이퍼파라미터 최적화\n",
    "# 하이퍼파라미터 검색 범위 설정\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'max_leaf_nodes': [10, 20, 30, None]\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용해 결정 트리 모델을 최적화\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 테스트 정확도 출력\n",
    "best_dt = grid_search.best_estimator_\n",
    "print(\"최적의 하이퍼파라미터:\", grid_search.best_params_)\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"결정 트리의 테스트 정확도:\", dt_accuracy)\n",
    "\n",
    "# 3. 랜덤 포레스트 구현\n",
    "# 랜덤 포레스트는 100개의 서브셋을 사용해 결정 트리를 훈련\n",
    "n_trees = 100\n",
    "random_forest = RandomForestClassifier(n_estimators=n_trees, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# 랜덤 포레스트 모델의 테스트 정확도 확인\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"랜덤 포레스트의 테스트 정확도:\", rf_accuracy)\n",
    "\n",
    "# 4. 다수결 앙상블\n",
    "# 100개의 결정 트리 예측값을 모으고 다수결 방식으로 최종 예측 생성\n",
    "y_preds = np.array([tree.predict(X_test) for tree in random_forest.estimators_])\n",
    "majority_votes = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=y_preds)\n",
    "\n",
    "# 다수결 앙상블 방식의 정확도 측정\n",
    "ensemble_accuracy = accuracy_score(y_test, majority_votes)\n",
    "print(\"다수결 앙상블 방식의 테스트 정확도:\", ensemble_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37107a9c-3633-4542-847b-825d4e40b926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
