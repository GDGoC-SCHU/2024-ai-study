# 과제3: 결정 트리와 랜덤 포레스트를 사용한 moons 데이터셋 분류

## 목차
1. [결정 트리(Decision Tree)](#결정-트리decision-tree)
2. [랜덤 포레스트(Random Forest)](#랜덤-포레스트random-forest)
3. [교차 검증 및 그리드 탐색](#교차-검증-및-그리드-탐색)
4. [과제](#과제)

---

## 1. 결정 트리(Decision Tree)
- **정의**: 데이터를 기준에 따라 분리하는 트리 구조의 모델입니다.
- **장점**: 직관적이고 해석이 쉬우며, 다양한 데이터 형태를 처리할 수 있습니다.
- **단점**: 과적합(overfitting)되기 쉬움.


## 2. 랜덤 포레스트(Random Forest)
- **정의**: 여러 개의 결정 트리를 결합한 앙상블 학습 방법입니다.
- **장점**:
  - 단일 결정 트리에 비해 과적합을 방지합니다.
  - 분산과 편향을 줄이며 일반화 성능을 높입니다.
- **작동 원리**:
  1. **데이터 샘플링**: 훈련 데이터의 랜덤 서브셋 생성(부트스트랩 샘플링).
  2. **랜덤성 도입**: 각 트리가 서로 다른 특성 집합을 사용.
  3. **다수결(Majority Voting)**: 모든 트리의 예측 결과를 결합해 최종 예측.


## 교차 검증 및 그리드 탐색
- **교차 검증(Cross Validation)**: 데이터를 여러 번 나눠 모델의 일반화 성능을 평가.
- **그리드 탐색(Grid Search)**: 여러 하이퍼파라미터 조합을 시도해 최적값을 찾음.

</br>
</br>
</br>

# 과제

## 목표
결정 트리를 사용해 moons 데이터셋 분류 문제를 해결하고, 랜덤 포레스트로 정확도를 향상시켜 보세요.

---

### 1. 데이터 준비
- `make_moons(n_samples=10000, noise=0.4)`를 사용해 데이터를 생성하세요.
- 데이터를 훈련 세트(80%)와 테스트 세트(20%)로 나누세요(`train_test_split` 사용).

### 2. 결정 트리 하이퍼파라미터 최적화
- `GridSearchCV`를 사용해 결정 트리의 `max_depth`, `max_leaf_nodes` 등 최적의 하이퍼파라미터를 찾으세요.
- 최적의 하이퍼파라미터로 훈련된 모델의 테스트 정확도를 확인하세요.

### 3. 랜덤 포레스트 구현
- 훈련 세트를 랜덤하게 샘플링한 서브셋을 생성하세요(100개의 서브셋).
- 각 서브셋에 대해 결정 트리를 훈련시키고 정확도를 확인하세요.

### 4. 다수결 앙상블
- 테스트 데이터에 대해 100개의 결정 트리의 예측값을 모으세요.
- 다수결 방식으로 최종 예측을 생성하고 정확도를 측정하세요.

---

### 예상 출력 예시
```plaintext
Best Parameters: {'max_depth': 6, 'max_leaf_nodes': 17, 'min_samples_split': 2}
Single Tree Accuracy: 0.8595
Average Single Tree Accuracy: 0.8057
Ensemble Accuracy: 0.8730
