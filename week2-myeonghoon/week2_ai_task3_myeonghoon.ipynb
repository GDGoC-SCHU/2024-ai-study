{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-1QlM1Gypxy",
        "outputId": "b8003452-f38b-45fa-da02-9b5a67643bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 10, 'max_leaf_nodes': 20, 'min_samples_split': 2}\n",
            "Single Tree Accuracy: 0.8700\n",
            "Average Single Tree Accuracy: 0.8643\n",
            "Ensemble Accuracy: 0.8700\n"
          ]
        }
      ],
      "source": [
        "# 과제3: 결정 트리와 랜덤 포레스트를 사용한 moons 데이터셋 분류\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. 데이터 준비\n",
        "# make_moons 함수로 10,000개의 샘플을 가진 데이터셋 생성 (노이즈 0.4 추가)\n",
        "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
        "\n",
        "# 데이터를 훈련 세트(80%)와 테스트 세트(20%)로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. 결정 트리 하이퍼파라미터 최적화\n",
        "# 결정 트리 분류기 초기화\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# GridSearchCV로 최적의 하이퍼파라미터를 찾기 위한 파라미터 설정\n",
        "param_grid = {\n",
        "    'max_depth': [5, 6, 10, 15, 20],\n",
        "    'max_leaf_nodes': [5, 10, 17, 20, 50],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# GridSearchCV를 사용하여 최적의 파라미터 탐색\n",
        "# 5-fold 교차 검증을 사용하여 각 파라미터 조합 평가\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# 최적의 하이퍼파라미터로 훈련된 모델 평가\n",
        "best_clf = grid_search.best_estimator_  # 최적의 모델 가져오기\n",
        "y_pred = best_clf.predict(X_test)      # 테스트 데이터에 대한 예측 수행\n",
        "single_tree_accuracy = accuracy_score(y_test, y_pred)  # 정확도 계산\n",
        "print(\"Single Tree Accuracy:\", f\"{single_tree_accuracy:.4f}\")\n",
        "\n",
        "# 3. 랜덤 포레스트 구현\n",
        "# 서브샘플의 개수 설정\n",
        "n_trees = 100  # 랜덤 포레스트를 구성할 결정 트리 개수\n",
        "n_instances = X_train.shape[0]  # 훈련 데이터의 샘플 수\n",
        "\n",
        "# 각 트리에서 사용할 서브샘플 생성 및 모델 훈련\n",
        "forest = []  # 랜덤 포레스트를 구성할 트리 저장 리스트\n",
        "accuracies = []  # 각 트리의 정확도를 저장할 리스트\n",
        "\n",
        "for _ in range(n_trees):\n",
        "    # 훈련 데이터에서 샘플링 (중복 허용, 즉 부트스트랩 샘플링)\n",
        "    indices = np.random.randint(0, n_instances, n_instances)  # 랜덤 인덱스 생성\n",
        "    X_subset, y_subset = X_train[indices], y_train[indices]   # 서브샘플 데이터 추출\n",
        "\n",
        "    # 결정 트리 초기화 및 훈련\n",
        "    tree_clf = DecisionTreeClassifier(max_depth=None, max_leaf_nodes=20, min_samples_split=2, random_state=None)\n",
        "    tree_clf.fit(X_subset, y_subset)\n",
        "\n",
        "    # 테스트 데이터로 예측 수행 및 정확도 저장\n",
        "    y_pred = tree_clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)  # 정확도 리스트에 추가\n",
        "\n",
        "    forest.append(tree_clf)  # 트리를 포레스트 리스트에 추가\n",
        "\n",
        "# 평균 단일 트리 정확도 출력\n",
        "average_tree_accuracy = np.mean(accuracies)  # 각 트리 정확도의 평균 계산\n",
        "print(\"Average Single Tree Accuracy:\", f\"{average_tree_accuracy:.4f}\")\n",
        "\n",
        "# 4. 다수결 앙상블\n",
        "# 테스트 데이터에 대한 모든 트리의 예측값 수집\n",
        "predictions = np.zeros((n_trees, X_test.shape[0]), dtype=np.int64)  # 모든 트리의 예측값을 저장할 배열\n",
        "\n",
        "for i, tree in enumerate(forest):\n",
        "    predictions[i] = tree.predict(X_test)  # 각 트리의 예측값 저장\n",
        "\n",
        "# 다수결 방식으로 최종 예측 생성\n",
        "# axis=0을 기준으로 각 샘플에 대해 가장 많이 등장한 클래스 선택\n",
        "final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "\n",
        "# 다수결 앙상블 모델의 정확도 계산\n",
        "ensemble_accuracy = accuracy_score(y_test, final_predictions)\n",
        "print(\"Ensemble Accuracy:\", f\"{ensemble_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single Tree Accuracy: 최적 하이퍼파라미터를 사용한 단일 결정 트리가 테스트 셋에서 87%의 정확도가 나타남\n",
        "결정 트리가 데이터의 주요 패턴을 잘 학습했음을 나타내지만 단일 트리는 랜덤 샘플링에 민감하고, 데이터의 특정 부분에 과적합될 가능성\n",
        "\n",
        "Average Single Tree Accuracy: 랜덤 샘플링된 100개의 서브셋에 대해 훈련된 개별 결정 트리의 정확도를 평균 낸 값\n",
        "단일 트리 정확도(87%)보다 약간 낮은 이유는 각 트리가 훈련 데이터의 서브셋만 사용하기 때문에, 데이터의 전체적인 분포를 완전히 반영하지 못하기 때문\n",
        "\n",
        "Ensemble Accuracy: 다수결 앙상블(Random Forest) 방식을 사용한 최종 모델의 정확도\n",
        "랜덤 포레스트의 다수결 앙상블은 개별 트리의 예측 편향을 줄이고, 더 높은 일반화 성능을 제공\n",
        "\n",
        "단일 결정 트리와 앙상블 모델의 성능 차이는 나타나지 않았는데,\n",
        "이는 make_moons 데이터셋이 비교적 간단한 문제이고, 최적화된 단일 트리도 이미 상당히 높은 성능을 제공하기 때문에 발생\n",
        "\n",
        "적절한 max_depth와 max_leaf_nodes 설정은 모델의 복잡도를 제어하여, 과적합을 방지하면서도 데이터를 충분히 학습하도록 도우며,\n",
        "min_samples_split의 기본값(2)은 이 데이터셋의 특성상 추가적인 최적화 없이도 좋은 성능을 제공한다."
      ],
      "metadata": {
        "id": "EqStHEGtEzpB"
      }
    }
  ]
}