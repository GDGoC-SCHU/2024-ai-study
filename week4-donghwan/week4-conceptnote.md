# week4 - concept note
## DNN(Deep Neural Network)
* DNN은 여러 은닉층을 가진 심층 신경망으로, 복잡한 패턴을 학습
* 이미지 처리, 자연어 처리 등 다양한 분야에 활용
* 학습 시간과 과적합, 해석의 어려움
### 활성화 함수 
* 시그모이드 함수: 대표적 활성화 함수 0 ~ 1로 입력신호의 총합을 바꿔줌(편향이동 o)
* 하이퍼볼릭 탄젠트 함수: 시그모이드 함수의 대체제 -1 ~ 1로 입력값의 총합을 바꿔줌(편향이동 x)
* ReLU gkatn: 0 이상인 값은 입력값으로 출력, 0 이하는 0으로 출력
### 배치 정규화
* 입력을 정규화 하여 학읍을 안정적이고 빠르게 만듬
* 기울기 소실 문제를 완화하고 과적합을 줄일 수 있음
* 작은 배치 크기에서는 성능이 떨어지고 추론시 계산 복잡성이 증가

## ANN(Artificial Neural Networks)
* 인간 뇌의 뉴런 구조를 모방한 기계 학습 모델
* 입력층, 은닉층, 출력층으로 구성되어 데이터 패턴을 학습
* 주로 이미지 분류, 예측, 자연어 처리 등의 분야에서 사용
### 퍼셉트론
* 단층 신경망으로 이진 문제를 해결하는 모델
* 입력값에 가중치를 곱해 활성화 함수가 출력값 계산
* 비선형 문제 해결에는 한계점 존재 -> 다중 퍼셉트론으로 해결
### 역전파 알고리즘
* 신경망의 가중치 학습 방법
*  출력과 실제 값 사이의 오차를 네트워크를 통해 전파하여 가중치를 조정
* 순전파에서 예측값을 계산하고, 출력층에서 오차를 계산한 후, 이를 역으로 전파하여 가중치를 수정
* 이 과정은 경사 하강법을 이용하여 최적화되며, 신경망 학습의 핵심적인 역할