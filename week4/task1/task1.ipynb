{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "32218d67",
      "metadata": {
        "id": "32218d67"
      },
      "source": [
        "# 심층 신경망(DNN) 훈련\n",
        "\n",
        "심층 신경망에선 모델이 복잡해질수록 hidden layer의 개수가 많은 신경망 모델을 학습시켜야 한다. 하지만 이러한 깊은 모델을 학습시키는데에는 다음과 같은 문제가 발생할 확률이 높다.\n",
        "\n",
        "- **그래디언트 소실**(vanishing gradient) 또는 **폭주**(exploding)가 발생할 수 있다.\n",
        "- 모델이 복잡하고 커질수록 **학습시간이 매우 느려진다**.\n",
        "- 모델이 복잡할수록 **오버피팅(overfitting)**될 위험이 크다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baf6f949",
      "metadata": {
        "id": "baf6f949"
      },
      "source": [
        "## 그래디언트 소실과 폭주 문제\n",
        "\n",
        "오차역전파에서 살펴보았듯이 역전파 알고리즘은 출력층(output layer)에서 입력층(input layer)로 오차 그래디언트(gradient)를 흘려 보내면서 각 뉴런의 입력값에 대한 손실함수의 그래디언트를 계산한다. 이렇게 계산된 그래디언트를 경사 하강법(gradient descent)단계에서 각 가중치 매개변수($\\mathbf{W}$)를 업데이트 해준다.\n",
        "\n",
        "하지만 아래의 그림과 같이 깊이가 깊은 심층신경망에서는 역전파 알고리즘이 입력층으로 전달됨에 따라 그래디언트가 점점 작아져 결국 가중치 매개변수가 업데이트 되지 않는 경우가 발생하게 된다. 이러한 문제를 **그래디언트 소실**(vanishing gradient)라고 한다.\n",
        "\n",
        "![그래디언트 소실](https://github.com/GDGoC-SCHU/2024-ai-study/blob/main/week4/task1/png/%EA%B7%B8%EB%9E%98%EB%94%94%EC%96%B8%ED%8A%B8%EC%86%8C%EC%8B%A4.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c25448ce",
      "metadata": {
        "id": "c25448ce"
      },
      "source": [
        "그래디언트 소실과는 반대로 역전파에서 그래디언트가 점점 커져 입력층으로 갈수록 가중치 매개변수가 기하급수적으로 커지게 되는 경우가 있는데 이를 **그래디언트 폭주**(exploding gradient)라고 하며, 이 경우에는 발산(diverse)하게되어 학습이 제대로 이루어지지 않는다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b45f98e",
      "metadata": {
        "id": "1b45f98e"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6713ee20",
      "metadata": {
        "id": "6713ee20"
      },
      "source": [
        "## 활성화 함수\n",
        "\n",
        "아래의 그림(출처: cs231n)에서 함수 $f$와 같이 입력 신호의 총합($\\sum_{i}^{}{w_ix_i + b}$)을 출력 신호로 변환하는 함수를 **활성화 함수**(activation function)라고 한다.\n",
        "\n",
        "![활성화 함수](https://github.com/GDGoC-SCHU/2024-ai-study/blob/main/week4/task1/png/%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98.png?raw=true)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b4ec7f8",
      "metadata": {
        "id": "3b4ec7f8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a3ed63ac",
      "metadata": {
        "id": "a3ed63ac"
      },
      "source": [
        "### - 시그모이드 함수\n",
        "\n",
        "시그모이드 함수($\\sigma$, sigmoid)는 대표적인 활성화 함수라고 할 수 있으며, 아래와 같은 식을 가지는 함수이다.\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1+e^{-x}}\n",
        "$$\n",
        "시그모이드 함수는 다음과 같은 특성을 가진다.\n",
        "\n",
        "- 입력 신호의 총합을 0에서 1사이의 값으로 바꿔준다.\n",
        "- 입력 신호의 값이 커질수록(작아질수록) 뉴런의 활성화률(firing rate)이 $1$(작아질 경우 $0$)로 수렴(saturation)한다.\n",
        "\n",
        "![시그모이드 함수](https://github.com/GDGoC-SCHU/2024-ai-study/blob/main/week4/task1/png/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C.png?raw=true)\n",
        "\n",
        "\n",
        "\n",
        "하지만, 위와 같은 특성 때문에 시그모이드 함수는 2가지 문제가 있다.\n",
        "\n",
        "- 입력의 절대값이 크게 되면 0이나 1로 수렴하게 되는데, 이러한 뉴런들은 **그래디언트를 소멸(kill) 시켜 버린다**. 그 이유는 수렴된 뉴런의 그래디언트 값은 0이기 때문에 역전파에서 0이 곱해지기 때문이다. 따라서, 역전파가 진행됨에 따라 아래 층(layer)에는 아무것도 전달되지 않는다.(시그모이드의 도함수는 $\\sigma(1- \\sigma)$이므로 함수의 값이 0이나 1에 가까우면 도함수의 결과가 매우 작아진다.)\n",
        "- **원점 중심이 아니다(Not zero-centered)**.  따라서, 평균이 $0$이 아니라 $0.5$이며, 시그모이드 함수는 항상 양수를 출력하기 때문에 출력의 가중치 합이 입력의 가중치 합보다 커질 가능성이 높다. 이것을 편향 이동(bias shift)이라 하며, 이러한 이유로 **각 레이어를 지날 때마다 분산이 계속 커져** 가장 높은 레이어에서는 활성화 함수의 출력이 0이나 1로 수렴하게 되어 그래디언트 소실 문제가 일어나게 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645d70de",
      "metadata": {
        "id": "645d70de"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5b2dadef",
      "metadata": {
        "id": "5b2dadef"
      },
      "source": [
        "### - 하이퍼볼릭 탄젠트 함수(tanh)\n",
        "\n",
        "하이퍼볼릭 탄젠트 함수(tanh, hyperbolic tangent)는 시그모이드 함수의 대체제로 사용할 수 있는 활성화 함수이며 아래와 같은 식을 갖는 함수이다.\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\text{tanh}(x) &= \\frac{1-e^{-x}}{1+e^{-x}} \\\\ &= \\frac{2}{1+e^{-2x}} -1\n",
        "\\end{align*}\n",
        "$$\n",
        "tanh함수는 시그모이드 함수($\\sigma$)와 유사하며, 아래와 같이 시그모이드 함수를 이용해 tanh 함수를 나타낼 수 있다.\n",
        "\n",
        "$$\n",
        "\\text{tanh}(x) = 2 \\sigma(2x)-1\n",
        "$$\n",
        "tanh함수는 아래의 그림과 같이 입력값의 총합을 -1에서 1사이의 값으로 변환해 주며, 원점 중심(zero-centered)이기 때문에, 시그모이드와 달리 편향 이동이 일어나지 않는다. 하지만, tanh함수 또한 입력의 절대값이 클 경우 -1이나 1로 수렴하게 되므로 그래디언트를 소멸시켜 버리는 문제가 있다.\n",
        "\n",
        "![탄젠트 함수](https://github.com/GDGoC-SCHU/2024-ai-study/blob/main/week4/task1/png/%ED%83%84%EC%A0%A0%ED%8A%B8.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Na5lFbrZRFAD"
      },
      "id": "Na5lFbrZRFAD"
    },
    {
      "cell_type": "markdown",
      "id": "a87f50ee",
      "metadata": {
        "id": "a87f50ee"
      },
      "source": [
        "### - ReLU (Rectified Linear Unit)\n",
        "\n",
        "ReLU(렐루, Rectified Linear Unit)는 시그모이드 계열과는 다른 활성화 함수이며,  아래의 식과 같이 입력이 0이상이면 입력을 그대로 출력하고, 0 이하이면 0을 출력하는 함수이다.\n",
        "$$\n",
        "\\text{ReLU}(x) = \\max(0, x)\n",
        "$$\n",
        "ReLU함수는 다음과 같은 특성을 가진다.\n",
        "\n",
        "- 0 이상인 곳에서는 수렴하는 구간이 없다.\n",
        "- 단순히 입력값을 그대로 출력으로 내보내기 때문에 시그모이드 함수에 비해 계산 속도가 빠르다.\n",
        "- sigmoid/tanh에 비해 stochastic gradient descent(SGD)에서 수렴속도가 6배나 빠르다고 한다.\n",
        "\n",
        "![렐루 함수](https://github.com/GDGoC-SCHU/2024-ai-study/blob/main/week4/task1/png/%EB%A0%90%EB%A3%A8.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44553079",
      "metadata": {
        "id": "44553079"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bcd263f7",
      "metadata": {
        "id": "bcd263f7"
      },
      "source": [
        "## 가중치 초기화 (Weight Initialization)\n",
        "\n",
        "신경망 학습에서 중요한것 중 하나는 학습 시킬 때의 가중치 초기값이다. 가중치 초기값을 어떻게 초기화 하느냐에 따라 학습의 성능이 달라진다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a980eca1",
      "metadata": {
        "id": "a980eca1"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2d79c86b",
      "metadata": {
        "id": "2d79c86b"
      },
      "source": [
        "### - 가중치 초기값이 0이거나 동일한 경우\n",
        "\n",
        "가중치의 초기값을 모두 0으로 초기화하거나 동일한 값으로 초기화할 경우 모든 뉴런의 동일한 출력값을 내보낸다. 그렇게 되면 역전파(backpropaation) 단계에서 각 뉴런이 모두 동일한 그래디언트 값을 가지게 된다. 학습이 잘 되려면, 각 뉴런이 가중치에 따라 비대칭(asymmetry, 어떤 뉴런은 가중치가 크고 어떤 뉴런은 가중치가 작게 되게끔)이어야 하는데 모든 뉴런이 동일한 그래디언트로 가중치 값이 변경되므로 뉴런의 개수가 아무리 많아도 뉴런이 하나뿐인 것처럼 작동하기 때문에 학습이 제대로 이루어지지 않는다.  따라서 가중치 초기값을 동일한 값으로 초기화 해서는 안 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b6fd08",
      "metadata": {
        "id": "f0b6fd08"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7137063f",
      "metadata": {
        "id": "7137063f"
      },
      "source": [
        "### - 작은 난수 (Small Random numbers) 인 경우\n",
        "\n",
        "가중치 초기값은 작은 값으로 초기화 해야하는데 그 이유는 활성화 함수가 sigmoid일 경우 만약 가중치 초기값(절대값)을 큰 값으로 한다면 0과 1로 수렴하기 때문에 그래디언트 소실이 발생하게 된다. 또한 활성화 함수가 ReLU일 경우 절대값이 클 경우 음수일 때는 dead ReLU 문제가 발생하고 양수일 때는 그래디언트 폭주가 일어나게 된다.\n",
        "\n",
        "따라서 가중치 초기값을 작게 초기화 해야하며 동일한 초기값을 가지지 않도록 랜덤하게 초기화 해야한다. 일반적으로 가중치 초기값은 평균이 0이고 표준편차가 0.01인 정규분포(가우시안 분포)를 따르는 값으로 랜덤하게 초기화 한다.\n",
        "\n",
        "이러한 가중치 초기화 방법은 얕은 신경망에서는 괜찮게 작동할지 모르지만 신경망의 깊이가 깊어질수록 문제가 발생하게 된다. 예를 들어 평균이 0이고 표준편차가 0.01인 정규분포(가우시안 분포)를 따르는 값으로 랜덤하게 초기화하고 tanh를 활성화 함수로 사용하였을 경우, 아래의 차트처럼 첫번째 hidden layer를 제외한 나머지 레이어들이 모두 0을 출력하고 있는것을 확인할 수 있다. 따라서 모든 뉴런의 그래디언트 값이 동일하기 때문에 학습이 이루어지지 않게 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1f69802",
      "metadata": {
        "id": "f1f69802"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7b83cae",
      "metadata": {
        "id": "f7b83cae"
      },
      "outputs": [],
      "source": [
        "# sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# ReLU\n",
        "def ReLU(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# tanh\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def weight_init(method=None):\n",
        "    '''가중치 초기화 함수\n",
        "\n",
        "    Args:\n",
        "        - method: 가중치 초기화 방법(large, small, xavier, relu)\n",
        "    Returns:\n",
        "        - np.array형태의 가중치 초기값\n",
        "    '''\n",
        "    w = 0\n",
        "    if method == 'large':\n",
        "        w = np.random.randn(node_num, node_num) * 1\n",
        "    elif method == 'small':\n",
        "        w = np.random.randn(node_num, node_num) * 0.01\n",
        "    elif method == 'xavier':\n",
        "        w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)  # Xavier init\n",
        "    elif method == 'he':\n",
        "        w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)  # He init\n",
        "\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78bd26e2",
      "metadata": {
        "id": "78bd26e2",
        "outputId": "7b26cdf7-9b15-4397-e5dc-492797e8f095"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_data = np.random.randn(1000, 100)  # 1000개의 데이터\n",
        "node_num = 100  # 각 은닉층의 노드(뉴런) 수\n",
        "hidden_layer_size = 5  # 은닉층이 5개\n",
        "activations = {}  # 이곳에 활성화 결과를 저장\n",
        "\n",
        "x = input_data\n",
        "\n",
        "for i in range(hidden_layer_size):\n",
        "    if i != 0:\n",
        "        x = activations[i-1]\n",
        "\n",
        "    w = weight_init('small')\n",
        "    a = np.dot(x, w)\n",
        "\n",
        "    # z = sigmoid(a)\n",
        "    # z = ReLU(a)\n",
        "    z = tanh(a)\n",
        "\n",
        "    activations[i] = z\n",
        "\n",
        "# 히스토그램 그리기\n",
        "for i, a in activations.items():\n",
        "    plt.subplot(1, len(activations), i+1)\n",
        "    plt.title(str(i+1) + \"-layer\")\n",
        "    if i != 0: plt.yticks([], [])\n",
        "#     plt.xlim(0.1, 1)\n",
        "    plt.ylim(0, 7000)\n",
        "    plt.hist(a.flatten(), 30, range=(-1,1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66b57541",
      "metadata": {
        "id": "66b57541"
      },
      "source": [
        "또한, 평균이 0이고 표준편차가 1인 정규분포를 따르는 값으로 랜덤하게 초기화하고 tanh를 활성화 함수로 사용하였을 경우에는 아래의 그림처럼 tanh의 출력이 -1과 1로 집중되면서 그래디언트 소실(vanishing gradient) 문제가 발생하게 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc435fa3",
      "metadata": {
        "id": "bc435fa3",
        "outputId": "9b1f0c4b-9412-4ce2-e67c-f2e664a0e0bf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range(hidden_layer_size):\n",
        "    if i != 0:\n",
        "        x = activations[i-1]\n",
        "\n",
        "    w = weight_init('large')\n",
        "    a = np.dot(x, w)\n",
        "\n",
        "    # z = sigmoid(a)\n",
        "    # z = ReLU(a)\n",
        "    z = tanh(a)\n",
        "\n",
        "    activations[i] = z\n",
        "\n",
        "# 히스토그램 그리기\n",
        "for i, a in activations.items():\n",
        "    plt.subplot(1, len(activations), i+1)\n",
        "    plt.title(str(i+1) + \"-layer\")\n",
        "    if i != 0: plt.yticks([], [])\n",
        "#     plt.xlim(0.1, 1)\n",
        "    plt.ylim(0, 7000)\n",
        "    plt.hist(a.flatten(), 30, range=(-1,1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1345d23b",
      "metadata": {
        "id": "1345d23b"
      },
      "source": [
        "따라서, 작은 난수로 가중치를 초기화 하는 방법 또한 심층 신경망(DNN)에서는 적합하지 않다고 할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2737cfe",
      "metadata": {
        "id": "b2737cfe"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7a0ccf48",
      "metadata": {
        "id": "7a0ccf48"
      },
      "source": [
        "### - Xavier 초기화와 He 초기화\n",
        "\n",
        "학습이 제대로 이루어지기 위해서는 각 뉴런의 활성화 함수 출력값이 고르게 분포되어 있어야 한다. 레이어와 레이어 사이에 다양한 데이터가 흘러야(forward, backprop) 신경망 학습이 효율적으로 이루어진다. 만약, 4.2에서와 같이 한쪽으로 치우친 데이터가 흐르게 되면 그래디언트 소실이나 모든 뉴런의 그래디언트 값이 동일해져 학습이 이루어지지 않는 문제가 발생한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6013618",
      "metadata": {
        "id": "b6013618"
      },
      "source": [
        "#### Xavier Initialization\n",
        "\n",
        "[Xavier Glorot과 Yoshua Bengio](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)는 적절한 데이터가 흐르기 위해서는 각 레이어의 출력에 대한 분산이 입력에 대한 분산과 같아야 하며, 역전파에서 레이어를 통과하기 전과 후의 그래디언트 분산이 동일해야 한다고 주장했다.  Glorot과 Bengio는 'Understanding the Difficulty of Training Deep Feedforward Neural Networks'라는 논문에서 아래의 식과 같은 가중치 초기값을 제안했는 데, 이러한 초기화 방법을 **Xavier Initialization** 라고 한다.\n",
        "\n",
        "Xavier 초기값은 **활성화 함수가 선형(linear)이라고 가정**한다. 아래의 그림에서 처럼 sigmoid 계열(sigmoid, tanh)의 활성화 함수는 좌우 대칭이며 가운데 부분이 선형인 함수로 볼 수 있다.\n",
        "\n",
        "이러한 가정을 토대로 sigmoid 활성화 함수에서의 Xavier initialization 식은 다음과 같다.\n",
        "\n",
        "- 평균이 0이고 표준편차 $\\sigma = \\sqrt{\\frac{2}{n_{\\text{inputs}} + n_{\\text{outputs}}}}$ 인 정규분포\n",
        "- 또는 $r = \\sqrt{\\frac{6}{n_{\\text{inputs}} + n_{\\text{outputs}}}}$ 일 때 $-r$과 $+r$ 사이의 균등분포\n",
        "- 입력의 연결 개수와 출력의 연결 개수가 비슷할 경우 $\\sigma = 1/\\sqrt{n_{\\text{inputs}}}$ 또는 $r = \\sqrt{3} / \\sqrt{n_{\\text{inputs}}}$ 를 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297a7bde",
      "metadata": {
        "id": "297a7bde"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f119a9d",
      "metadata": {
        "id": "0f119a9d",
        "outputId": "6de082e8-2b0b-4ec7-f00e-836f0e39c4d4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_data = np.random.randn(1000, 100)  # 1000개의 데이터\n",
        "node_num = 100  # 각 은닉층의 노드(뉴런) 수\n",
        "hidden_layer_size = 5  # 은닉층이 5개\n",
        "activations = {}  # 이곳에 활성화 결과를 저장\n",
        "\n",
        "x = input_data\n",
        "\n",
        "for i in range(hidden_layer_size):\n",
        "    if i != 0:\n",
        "        x = activations[i-1]\n",
        "\n",
        "    w = weight_init('xavier')\n",
        "    a = np.dot(x, w)\n",
        "\n",
        "    # z = sigmoid(a)\n",
        "    # z = ReLU(a)\n",
        "    z = tanh(a)\n",
        "\n",
        "    activations[i] = z\n",
        "\n",
        "# 히스토그램 그리기\n",
        "for i, a in activations.items():\n",
        "    plt.subplot(1, len(activations), i+1)\n",
        "    plt.title(str(i+1) + \"-layer\")\n",
        "    if i != 0: plt.yticks([], [])\n",
        "#     plt.xlim(0.1, 1)\n",
        "    plt.ylim(0, 7000)\n",
        "    plt.hist(a.flatten(), 30, range=(-1,1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "793863ed",
      "metadata": {
        "id": "793863ed"
      },
      "source": [
        "tanh 활성화 함수에 xavier 초기값을 설정했을 때, 4.2에서 작은 난수 초기화 했을 때보다 넓게 분포되어 있는것을 확인할 수 있다.\n",
        "\n",
        "텐서플로에서는 이러한 Xavier 초기값을 쉽게 사용할 수 있도록 `tf.contrib.xavier_initializer`를 제공한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f6bc497",
      "metadata": {
        "id": "4f6bc497"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "73dfae0b",
      "metadata": {
        "id": "73dfae0b"
      },
      "source": [
        "#### He Initialization\n",
        "\n",
        "하지만 Xavier 초기값은 ReLU 활성화 함수에서는 아래의 그림처럼 레이어가 깊어질 수록 출력값이 0으로 치우치는 문제가 발생한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fc90320",
      "metadata": {
        "id": "8fc90320",
        "outputId": "e1fc0805-7118-4b90-ae98-c2ff9f561c2b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_data = np.random.randn(1000, 100)  # 1000개의 데이터\n",
        "node_num = 100  # 각 은닉층의 노드(뉴런) 수\n",
        "hidden_layer_size = 5  # 은닉층이 5개\n",
        "activations = {}  # 이곳에 활성화 결과를 저장\n",
        "\n",
        "x = input_data\n",
        "\n",
        "for i in range(hidden_layer_size):\n",
        "    if i != 0:\n",
        "        x = activations[i-1]\n",
        "\n",
        "    w = weight_init('xavier')\n",
        "    a = np.dot(x, w)\n",
        "\n",
        "    # z = sigmoid(a)\n",
        "    z = ReLU(a)\n",
        "    # z = tanh(a)\n",
        "\n",
        "    activations[i] = z\n",
        "\n",
        "# 히스토그램 그리기\n",
        "for i, a in activations.items():\n",
        "    plt.subplot(1, len(activations), i+1)\n",
        "    plt.title(str(i+1) + \"-layer\")\n",
        "    if i != 0: plt.yticks([], [])\n",
        "#     plt.xlim(0.1, 1)\n",
        "    plt.ylim(0, 7000)\n",
        "    plt.hist(a.flatten(), 30, range=(0,1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63ef6551",
      "metadata": {
        "id": "63ef6551"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1482f25e",
      "metadata": {
        "id": "1482f25e"
      },
      "source": [
        "Kaiming He는 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classifcation' 논문에서 ReLU에 적합한 초기값을 제안했는 데, 이를 그의 이름을 따 **He 초기값**이라고 하며 다음과 같은 식이다.\n",
        "\n",
        "- 평균이 0이고 표준편차 $\\sigma = \\sqrt{2} \\cdot \\sqrt{\\frac{2}{n_{\\text{inputs}} + n_{\\text{outputs}}}}$인 정규분포\n",
        "- 또는 $r = \\sqrt{2} \\cdot \\sqrt{\\frac{6}{n_{\\text{inputs}} + n_{\\text{outputs}}}}$ 일 때 $-r$과 $+r$ 사이의 균등분포\n",
        "- 입력의 연결 개수와 출력의 연결 개수가 비슷할 경우 $\\sigma = \\sqrt{2}/\\sqrt{n_{\\text{inputs}}}$ 또는 $r = \\sqrt{2} \\cdot \\sqrt{3} / \\sqrt{n_{\\text{inputs}}}$ 를 사용\n",
        "\n",
        "위의 식에서 알 수있듯이, He 초기값은 Xavier 초기값에서 $\\sqrt{2}$ 배 해줬다는 것을 확인할 수 있다. 그 이유는 ReLU는 입력이 음수일 때 출력이 전부 0이기 때문에 더 넓게 분포시키기 위해서이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b245ef",
      "metadata": {
        "id": "c1b245ef",
        "outputId": "34e05c9f-10a6-4c98-cc3b-d501ec6776a3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_data = np.random.randn(1000, 100)  # 1000개의 데이터\n",
        "node_num = 100  # 각 은닉층의 노드(뉴런) 수\n",
        "hidden_layer_size = 5  # 은닉층이 5개\n",
        "activations = {}  # 이곳에 활성화 결과를 저장\n",
        "\n",
        "x = input_data\n",
        "\n",
        "for i in range(hidden_layer_size):\n",
        "    if i != 0:\n",
        "        x = activations[i-1]\n",
        "\n",
        "    w = weight_init('he')\n",
        "    a = np.dot(x, w)\n",
        "\n",
        "    # z = sigmoid(a)\n",
        "    z = ReLU(a)\n",
        "    # z = tanh(a)\n",
        "\n",
        "    activations[i] = z\n",
        "\n",
        "# 히스토그램 그리기\n",
        "for i, a in activations.items():\n",
        "    plt.subplot(1, len(activations), i+1)\n",
        "    plt.title(str(i+1) + \"-layer\")\n",
        "    if i != 0: plt.yticks([], [])\n",
        "#     plt.xlim(0.1, 1)\n",
        "    plt.ylim(0, 7000)\n",
        "    plt.hist(a.flatten(), 30, range=(0,1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d16c02",
      "metadata": {
        "id": "57d16c02"
      },
      "source": [
        "He 초기값 또한 텐서플로에서 쉽게 사용할 수 있도록 `tf.keras.initializers.he_normal`과 `tf.keras.initializers.he_uniform`을 제공한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40df0982",
      "metadata": {
        "id": "40df0982"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e3800f71",
      "metadata": {
        "id": "e3800f71"
      },
      "source": [
        "## Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e41fc686",
      "metadata": {
        "id": "e41fc686"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 일관된 출력을 위해 유사난수 초기화\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# 한글출력\n",
        "# matplotlib.rc('font', family='AppleGothic')  # MacOS\n",
        "matplotlib.rc('font', family='Malgun Gothic')  # Windows\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e059edf",
      "metadata": {
        "id": "3e059edf"
      },
      "source": [
        "# 배치 정규화(BN, Batch Normalization)\n",
        "\n",
        "심층 신경망 학습에서는 활성화 함수로는 ReLU를 사용하고 He 초기화를 통해 학습 초기 단계에서의 그래디언트 소실/폭주 문제를 줄일 수 있었지만, 이러한 문제가 학습하는 동안에 또 다시 발생할 가능성이 있다.\n",
        "\n",
        "2015년 Sergety Ioffe와 Christian Szegedy는 ['Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift'](https://arxiv.org/pdf/1502.03167v3.pdf)라는 논문에서 **배치 정규화**(BN, Batch Normalization)를 제안했다.  배치 정규화는 각 층의 활성화 함수의 출력값 분포가 골고루 분포되도록 '강제'하는 방법으로, 각 층에서의 활성화 함수 출력값이 정규분포(normal distribution)를 이루도록 하는 방법이다.\n",
        "\n",
        "즉 학습하는 동안 이전 레이어에서의 가중치 매개변수가 변함에 따라 활성화 함수 출력값의 분포가 변화하는 **내부 공변량 변화(Internal Covariate Shift) 문제를 줄이는 방법**이 바로 배치 정규화 기법이다.\n",
        "\n",
        "배치 정규화는 아래의 그림과 같이 미니배치(mini-batch)의 데이터에서 각 feature(특성)별 평균($\\mu$, mean)과 분산($\\sigma^{2}$, variance)을 구한 뒤 정규화(normalize) 해준다.\n",
        "\n",
        "![배치정규화](https://github.com/GDGoC-SCHU/2024-ai-study/blob/main/week4/task1/png/%EB%B0%B0%EC%B9%98%EC%A0%95%EA%B7%9C%ED%99%94.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de83901a",
      "metadata": {
        "id": "de83901a"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "873fb0d7",
      "metadata": {
        "id": "873fb0d7"
      },
      "source": [
        "일반적으로 배치 정규화는 아래의 그림과 같이 Fully Connected(FC)나 Convolutional layer 바로 다음, 활성화 함수를 통과하기 전에 배치 정규화(BN)레이어를 삽입하여 사용한다.\n",
        "\n",
        "![배치정규화 레이어](https://github.com/GDGoC-SCHU/2024-ai-study/blob/main/week4/task1/png/%EB%B0%B0%EC%B9%98%EC%A0%95%EA%B7%9C%ED%99%94_%EB%A0%88%EC%9D%B4%EC%96%B4.png?raw=true)\n",
        "\n",
        "\n",
        "배치 정규화는 미니배치(mini-batch)를 단위로 데이터의 분포가 평균($\\mu$, mean)이 0, 분산($\\sigma^{2}$, variance)이 1이 되도록 정규화(normalization)한다.  수식은 다음과 같다.\n",
        "\n",
        "- **Input** : 미니배치 $B = \\{ x_1, x_2, \\dots, x_m \\}$ 개의 입력 데이터, 학습 될 파라미터인 $\\gamma, \\beta$\n",
        "- **Output** : $\\{ y_i = \\text{BN}_{\\gamma, \\beta}(x_i) \\}$\n",
        "\n",
        "$$\n",
        "\\begin{eqnarray*} \\mu _{ B } & \\leftarrow  & \\frac { 1 }{ m } \\sum _{ i=1 }^{ m }{ x_{ i } } & \\text{// mini-batch mean}  \\\\ \\sigma _{ B }^{ 2 } & \\leftarrow  & \\frac { 1 }{ m } \\sum _{ i=1 }^{ m }{ \\left( x_{ i }-\\mu _{ B } \\right) ^{ 2 } } & \\text{// mini-batch variance}  \\\\ \\hat { x } _{ i } & \\leftarrow  & \\frac { x_{ i }-\\mu _{ B } }{ \\sqrt { \\sigma _{ B }^{ 2 }+\\varepsilon }} & \\text{// normalize} \\\\ y_{i} & \\leftarrow & \\gamma \\hat{x}_{i} + \\beta \\equiv \\text{BN}_{\\gamma, \\beta}(x_i) & \\text{// scale and shift} \\end{eqnarray*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecfe249c",
      "metadata": {
        "id": "ecfe249c"
      },
      "source": [
        "- $\\mu_B$ : 미니배치 $B$에 대한 평균\n",
        "- $\\sigma_B$ : 미니배치 $B$에 대한 표준편차\n",
        "- $m$ : 미니배치 데이터 개수\n",
        "- $\\hat{x}_i$ : 평균이 0, 분산이 1로 정규화된 입력 데이터\n",
        "- $\\gamma$ : 정규화된 데이터에 대한 스케일(scale) 조정 파라미터\n",
        "- $\\beta$ : 정규화된 데이터에 대한 이동(shift) 조정 파라미터\n",
        "- $\\varepsilon$ : 분모가 0이 되는 것을 막기 위한 작은 숫자 ($10^{-5}$)\n",
        "- $y_i$ : $\\text{BN}$ 연산의 출력 결과"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c212376",
      "metadata": {
        "id": "1c212376"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7a31b671",
      "metadata": {
        "id": "7a31b671"
      },
      "source": [
        "### - Scale($\\gamma$)과 Shift($\\beta$)를 해주는 이유\n",
        "\n",
        "위의 식에서 입력 데이터($x_i$)에 대해 정규화(normalization, $\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_{B}^{2}+\\varepsilon}}$)를 하게 되면, $\\hat{x}_i$의 값이 대부분 0에 가까운 값이 될 것이다. 만약, 이러한 정규화된 입력 데이터 $\\hat{x}_{i}$가 시그모이드(sigmoid) 활성화 함수의 입력값으로 들어가게 되면, 비선형(nonlinearity) 함수인 sigmoid가 선형(linearity)구간에 빠지게 된다(sigmoid 함수는 0 부근에서 선형성을 띤다). 이러한 문제를 해결하기 위해서 아래의 식과 같이 정규화된 입력 데이터 $x_i$에 scaling과 shifting해주는 $\\gamma$와 $\\beta$를 적용 해준다.\n",
        "\n",
        "$$\n",
        "y_i = \\gamma \\hat{x}_i + \\beta\n",
        "$$\n",
        "\n",
        "\n",
        " $\\gamma$와 $\\beta$를 다르게 표현하면 $\\hat{x}_i$에 대한 가중치($\\gamma$) 와 편향(bias, $\\beta$)라고 볼 수 있으며,  $\\gamma$와 $\\beta$는 초기값으로 $\\gamma=1, \\beta=0$으로 시작해(즉, 초기에는 입력값 그대로 학습), 학습 과정에서 역전파(backprop)에 의해 적합한 값으로 조정된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "016f2183",
      "metadata": {
        "id": "016f2183"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5f26d92e",
      "metadata": {
        "id": "5f26d92e"
      },
      "source": [
        "### - 테스트 단계에서의 BN\n",
        "\n",
        "테스트 단계(추론 단계처럼 데이터가 하나씩 주입된다고 가정)나 추론 단계에서는 평균($\\mu_B$)과 표준편차($\\sigma_{B}$)를 계산할 미니배치가 없기 때문에 전체 Training Set의 평균과 표준편차를 사용한다. 하지만, 엄청나게 많은 전체 Training set에 대한 평균과 표준편차를 계산하기에는 무리기 때문에, 아래의 식과 같이 각 $n$개의 미니배치에 대한 평균과 표준편차를 이용해 전체 Training Set의 평균과 표준편차를 대신한다.\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\hat{\\mu} &= \\frac{1}{n} \\sum_{i=1}^{n}{\\mu_{B}^{(i)}} \\\\ \\hat{\\sigma} &= \\frac{1}{n} \\sum_{i=1}^{n}{\\sigma_{B}^{(i)}}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "\n",
        "위와 같은 방법 대신, 모델 학습 단계에서 **지수 감소**(exponential decay) 이동 평균법(moving average)을 사용하여 평균과 표준편차를 계산할 수 있다.\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\hat{\\mu} & \\leftarrow \\alpha \\hat{\\mu} + \\left(1 - \\alpha \\right)\\mu_{B}^{(i)} & \\text{// moving mean}\\\\ \\hat{\\sigma} & \\leftarrow \\alpha \\hat{\\sigma} + \\left( 1 - \\alpha \\right) \\sigma_{B}^{(i)} & \\text{// moving stddev}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "\n",
        "위의 식에서 $\\alpha$는 모멘텀(momentum)값으로 일반적으로 1에 가까운 0.9, 0.99, 0.999로 설정한다.  이러한 moving mean과 moving stddev는 학습 단계에서 매 미니배치마다 업데이트 해준다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb0c196",
      "metadata": {
        "id": "9bb0c196"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e6544b67",
      "metadata": {
        "id": "e6544b67"
      },
      "source": [
        "### - 배치 정규화의 장점\n",
        "\n",
        "Batch Normalization(BN)은 논문에서 실험했던 모든 DNN의 성능이 크게 향상 시켰다. BN은 다음과 같은 장점들이 있다.\n",
        "\n",
        "- tanh나 sigmoid 같은 활성화 함수에 대해 그래디언트 소실(vanishing gradient)문제가 감소한다.\n",
        "- 가중치 초기화에 덜 민감하다. 가중치 초기값에 크게 의존하지 않기 때문에 가중치 초기화 기법에 대해 크게 신경 쓰지 않아도 된다.\n",
        "- 학습률(learning rate)를 크게 잡아도 gradient descent가 잘 수렴한다.\n",
        "- 오버피팅을 억제한다. BN이 마치 Regularization 역할을 하기 때문에 드롭아웃(Dropout)과 같은 규제기법에 대한 필요성이 감소한다.  하지만, BN로 인한 규제는 효과가 크지 않기 때문에 드롭아웃을 함께 사용하는 것이 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c9456c8",
      "metadata": {
        "id": "1c9456c8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e348bab4",
      "metadata": {
        "id": "e348bab4"
      },
      "source": [
        "# 텐서플로에서 Batch Normalization 구현하기\n",
        "\n",
        "텐서플로(TensorFlow)에서는 `tf.nn.batch_normalization()`과 `tf.layers.batch_normalization()`을 통해 두 개의 Batch Normalization을 제공한다. 하지만, `tf.nn.batch_normalization`은 평균과 표준편차(학습할 때는 미니배치, 테스트할 때는 전체 데이터셋)를 직접 계산한 뒤 인자로 전달해줘야 하며, scaling과 shifting을 위한 $\\gamma, \\beta$를 만들어 줘야한다. 반면, `tf.layers.batch_normalization`은 이러한 작업들을 모두 처리해 주기 때문에 이것을 사용하는 것이 좋다.\n",
        "\n",
        "이제, `tf.layers.batch_normalization`을 이용하여 MNIST 데이터셋을 분류하는 DNN을 구현해 보도록 하자. DNN의 구성은 아래의 그림과 같이 784개의 입력층(input) → 300개 노드의 은닉층(hidden1) → 100개 노드의 은닉층(hidden2) → 10개의 출력층(output)으로 구성되어 있다.   \n",
        "\n",
        "![배치정규화 텐서플로](https://github.com/GDGoC-SCHU/2024-ai-study/blob/main/week4/task1/png/%EB%B0%B0%EC%B9%98%EC%A0%95%EA%B7%9C%ED%99%94_%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C.png?raw=true)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "471130d1",
      "metadata": {
        "id": "471130d1"
      },
      "source": [
        "### 1. MNIST DataSet Load\n",
        "\n",
        "먼저, 학습과 테스트에 사용할 MNIST 데이터셋을 로드한 뒤 랜덤하게 미니배치 크기만큼 가져오기 위한 `shuffle_batch()` 함수를 구현한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5739833e",
      "metadata": {
        "id": "5739833e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# MNIST Load\n",
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Train & TestSet reshape\n",
        "train_x = train_x.astype(np.float32).reshape(-1, 28*28) / 255.\n",
        "train_y = train_y.astype(np.int32)\n",
        "test_x = test_x.astype(np.float32).reshape(-1, 28*28) / 255.\n",
        "test_y = test_y.astype(np.int32)\n",
        "\n",
        "# Split Validation set from Train set\n",
        "valid_x, train_x = train_x[:5000], train_x[5000:]\n",
        "valid_y, train_y = train_y[:5000], train_y[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316f7d5f",
      "metadata": {
        "id": "316f7d5f"
      },
      "outputs": [],
      "source": [
        "def shuffle_batch(inputs, labels, batch_size):\n",
        "    rnd_idx = np.random.permutation(len(inputs))\n",
        "    n_batches = len(inputs) // batch_size\n",
        "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
        "        batch_x, batch_y = inputs[batch_idx], labels[batch_idx]\n",
        "        yield batch_x, batch_y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42d1717e",
      "metadata": {
        "id": "42d1717e"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0d24c522",
      "metadata": {
        "id": "0d24c522"
      },
      "source": [
        "### 2. NN 구성하기\n",
        "\n",
        "`tf.layers.batch_normalization()`처럼 배치 정규화가 반복해서 사용하기 때문에 코드 중복을 줄이기 위해 Python의 내장 모듈인 `functools`모듈 안에 있는 `partial()`함수를 사용해서 배치 정규화를 적용한다.\n",
        "\n",
        "`tf.layers.batch_normalization`로 배치 정규화를 사용할 경우, '1.2 테스트(추론) 단계에서의 BN'에서 살펴본 moving mean과 moving variance를 업데이트를 해주기 위해 `tf.GraphKeys.UPDATE_OPS`를 사용해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fd1f59b",
      "metadata": {
        "id": "7fd1f59b"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "reset_graph()\n",
        "################\n",
        "# layer params #\n",
        "################\n",
        "n_inputs = 28*28\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 100\n",
        "n_outputs = 10\n",
        "batch_norm_momentum = 0.9\n",
        "\n",
        "# input layer\n",
        "inputs = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
        "# output layer\n",
        "labels = tf.placeholder(tf.int32, shape=[None], name='labels')\n",
        "# BN에 사용하기 위한 학습 유무\n",
        "training = tf.placeholder_with_default(False, shape=[], name=\"training\")\n",
        "\n",
        "with tf.name_scope('dnn'):\n",
        "    # batch normalization layer using partial\n",
        "    batch_norm_layer = partial(\n",
        "            tf.layers.batch_normalization,\n",
        "            training=training,\n",
        "            momentum=batch_norm_momentum)\n",
        "\n",
        "    # 1st - hidden\n",
        "    hidden1 = tf.layers.dense(inputs, n_hidden1, name=\"hidden1\")\n",
        "    # batch norm\n",
        "    bn1 = batch_norm_layer(hidden1)\n",
        "    # activation function\n",
        "    bn1_act = tf.nn.elu(bn1)\n",
        "\n",
        "    # 2nd - hidden\n",
        "    hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
        "    bn2 = batch_norm_layer(hidden2)\n",
        "    bn2_act = tf.nn.elu(bn2)\n",
        "\n",
        "    # outputs\n",
        "    logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
        "    logits = batch_norm_layer(logits_before_bn)\n",
        "\n",
        "with tf.name_scope('loss'):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name='loss')\n",
        "\n",
        "\n",
        "################\n",
        "# Hyper-params #\n",
        "################\n",
        "learning_rate = 0.01\n",
        "n_epochs = 5\n",
        "batch_size = 50\n",
        "\n",
        "# moving mean & variance update\n",
        "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "with tf.control_dependencies(update_ops):\n",
        "    with tf.name_scope('train'):\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "        train_op = optimizer.minimize(xentropy)\n",
        "\n",
        "with tf.name_scope('eval'):\n",
        "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02adcf6f",
      "metadata": {
        "id": "02adcf6f"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8c654d4d",
      "metadata": {
        "id": "8c654d4d"
      },
      "source": [
        "### 3. 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46069525",
      "metadata": {
        "id": "46069525",
        "outputId": "ed5b7e18-cf94-4c3e-d21d-14ac33e849e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 000, valid. Acc: 0.9582\n",
            "epoch: 001, valid. Acc: 0.9728\n",
            "epoch: 002, valid. Acc: 0.9740\n",
            "epoch: 003, valid. Acc: 0.9790\n",
            "epoch: 004, valid. Acc: 0.9798\n"
          ]
        }
      ],
      "source": [
        "with tf.Session() as sess:\n",
        "    tf.global_variables_initializer().run()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for batch_x, batch_y in shuffle_batch(train_x, train_y, batch_size):\n",
        "            sess.run(train_op, feed_dict={inputs: batch_x,\n",
        "                                          labels:batch_y,\n",
        "                                          training: True})\n",
        "\n",
        "        # validation\n",
        "        accuracy_val = accuracy.eval(feed_dict={inputs: valid_x, labels: valid_y})\n",
        "        print('epoch: {:03d}, valid. Acc: {:.4f}'.format(epoch, accuracy_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4648dd9",
      "metadata": {
        "id": "a4648dd9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "707325a3",
      "metadata": {
        "id": "707325a3"
      },
      "source": [
        "# Task1:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, ReLU, Dropout\n",
        "\n",
        "# 배치 정규화를 포함한 딥러닝 모델 정의 함수\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        # TODO: 첫 번째 Dense 층(유닛 수: 256)과 적절한 입력 형태를 추가하세요.\n",
        "        #\n",
        "\n",
        "        # TODO: 첫 번째 Dense 층 다음에 배치 정규화를 추가하세요.\n",
        "        #\n",
        "\n",
        "        # TODO: 첫 번째 배치 정규화 다음에 ReLU 활성화 함수를 추가하세요.\n",
        "        #\n",
        "\n",
        "        # TODO: 유닛 수가 128인 Dense 층을 추가하세요.\n",
        "        #\n",
        "\n",
        "        # 해당 층에 배치 정규화와 ReLU를 추가합니다.\n",
        "        #\n",
        "        #\n",
        "\n",
        "        # TODO: 드롭아웃 층(드롭아웃 비율: 0.3)을 추가하세요.\n",
        "        #\n",
        "\n",
        "        # TODO: 유닛 수가 64인 Dense 층을 추가하세요.\n",
        "        #\n",
        "\n",
        "        # 해당 층에 배치 정규화와 ReLU를 추가합니다.\n",
        "        #\n",
        "\n",
        "        # TODO: 유닛 수가 10인 출력층(Dense)과 softmax 활성화 함수를 추가하세요.\n",
        "        #\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# MNIST 데이터셋을 로드하고 전처리합니다.\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# TODO: 데이터 형태를 (784,)로 변환하고, 0~1 범위로 정규화하세요.\n",
        "#\n",
        "#\n",
        "\n",
        "# TODO: Adam 옵티마이저, sparse categorical crossentropy 손실 함수, accuracy 메트릭으로 모델을 컴파일하세요.\n",
        "model = create_model()\n",
        "model.compile(\n",
        "    #\n",
        "    #\n",
        "    #\n",
        ")\n",
        "\n",
        "# TODO: 배치 크기를 64로, 에포크 수를 5로 설정하여 모델을 훈련하세요.\n",
        "#\n",
        "\n",
        "\n",
        "# TODO: 모델을 평가하고 테스트 정확도를 출력하세요.\n",
        "#\n"
      ],
      "metadata": {
        "id": "N2xjr-VwtH5l"
      },
      "id": "N2xjr-VwtH5l",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}