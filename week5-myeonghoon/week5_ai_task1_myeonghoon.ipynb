{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task1:\n",
        "1. 기존 모델 생성 및 저장\n",
        "아래 코드를 실행하여 my_model.h5 파일을 생성하세요. 이 파일은 학습된 기본 모델로, Transfer Learning 과제에서 활용됩니다.\n",
        "\n",
        "2. Transfer Learning 과제\n",
        "이제 학습된 모델(my_model.h5)을 기반으로 Transfer Learning을 수행합니다.\n",
        "\n",
        "3. 과제 목표\n",
        "my_model.h5에서 hidden1과 hidden2 레이어를 동결(Freezing) 처리합니다.\n",
        "새로운 hidden4와 logits 레이어를 추가하여 모델을 확장합니다.\n",
        "확장된 모델을 사용하여 MNIST 데이터셋을 학습하고, 테스트 데이터로 성능을 평가합니다.\n",
        "4. 과제 지시사항\n",
        "my_model.h5 파일을 불러와 hidden1, hidden2, hidden3를 재사용하고, 새로운 hidden4와 logits를 추가하세요.\n",
        "hidden1과 hidden2는 동결 처리하여 학습되지 않도록 설정합니다.\n",
        "Transfer Learning 모델을 Adam 옵티마이저, Sparse Categorical Crossentropy 손실 함수, Accuracy 메트릭으로 컴파일하세요.\n",
        "모델을 학습한 후 테스트 정확도를 출력하세요."
      ],
      "metadata": {
        "id": "fKGg_vWY5i0F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J2-ZiIu4oV7",
        "outputId": "5acd034f-96a9-4be6-a461-703b1c7c1c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8391 - loss: 0.5441\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9612 - loss: 0.1303\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9743 - loss: 0.0828\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.0631\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# 기존 모델 생성 및 저장\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 기존 모델 생성\n",
        "def create_base_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(784,), name='hidden1'),\n",
        "        Dense(64, activation='relu', name='hidden2'),\n",
        "        Dense(32, activation='relu', name='hidden3'),\n",
        "        Dense(10, activation='softmax', name='output'),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# MNIST 데이터 로드 및 전처리\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0\n",
        "\n",
        "# 모델 생성 및 컴파일\n",
        "base_model = create_base_model()\n",
        "base_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "base_model.fit(x_train, y_train, batch_size=64, epochs=5)\n",
        "\n",
        "# 모델 저장\n",
        "base_model.save('./my_model.h5')  # 'my_model.ckpt'는 Keras에서 'h5' 형식으로 저장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "# TODO: 저장된 기존 모델('my_model.h5')을 불러오세요.\n",
        "base_model = load_model('my_model.h5')\n",
        "\n",
        "# TODO: 새로운 입력 레이어를 정의하세요. (입력 형태: (784,))\n",
        "input_layer = Input(shape=(784,))\n",
        "\n",
        "# TODO: 기존 모델에서 hidden1부터 hidden3까지를 가져와 연결하세요.\n",
        "hidden1 = base_model.get_layer('hidden1')(input_layer)\n",
        "hidden2 = base_model.get_layer('hidden2')(hidden1)\n",
        "hidden3 = base_model.get_layer('hidden3')(hidden2)\n",
        "\n",
        "# TODO: hidden1과 hidden2 레이어를 동결하세요.\n",
        "for layer in [base_model.get_layer('hidden1'), base_model.get_layer('hidden2')]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# TODO: 새로운 hidden4와 logits 레이어를 추가하여 모델을 확장하세요.\n",
        "hidden4 = Dense(128, activation='relu', name='hidden4')(hidden3)\n",
        "logits = Dense(10, activation='softmax', name='logits')(hidden4)\n",
        "\n",
        "# TODO: 새로운 Transfer Learning 모델을 생성하세요.\n",
        "transfer_model = Model(inputs=input_layer, outputs=logits)\n",
        "\n",
        "# TODO: 모델을 컴파일하세요. (옵티마이저: Adam, 손실 함수: Sparse Categorical Crossentropy, 메트릭: Accuracy)\n",
        "transfer_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# TODO: MNIST 데이터셋을 로드하고 전처리하세요. (데이터를 (784,)로 변환 및 정규화)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784) / 255.0\n",
        "x_test = x_test.reshape(-1, 784) / 255.0\n",
        "\n",
        "# TODO: 모델을 학습하세요. (배치 크기: 64, 에포크: 5, 검증 데이터: 20%)\n",
        "history = transfer_model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# TODO: 모델을 평가하고 테스트 정확도를 출력하세요.\n",
        "test_loss, test_acc = transfer_model.evaluate(x_test, y_test)\n",
        "print(f\"테스트 정확도: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1l7eof15rrn",
        "outputId": "babd935c-1cf5-4b5a-da1f-f88af6428472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.3070 - val_accuracy: 0.9903 - val_loss: 0.0313\n",
            "Epoch 2/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0317 - val_accuracy: 0.9903 - val_loss: 0.0300\n",
            "Epoch 3/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0264 - val_accuracy: 0.9921 - val_loss: 0.0260\n",
            "Epoch 4/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0259 - val_accuracy: 0.9906 - val_loss: 0.0308\n",
            "Epoch 5/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0262 - val_accuracy: 0.9914 - val_loss: 0.0259\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9758 - loss: 0.0932\n",
            "테스트 정확도: 0.9788\n"
          ]
        }
      ]
    }
  ]
}